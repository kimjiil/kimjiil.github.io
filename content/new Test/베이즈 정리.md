---
imageNameKey: 2024-09-09-19-37
tags:
  - Probability_and_Statistics
  - DeepLearning
  - Bayes_Rule
---
## 베이즈 정리의 의미
- **H** : Hyphothesis 가설, 어떤 사건이 발생했다는 주장
- **E** : Evidence 새로운 정보
- $p(H)$ : 어떤 사건이 발생했다는 주장에 대한 신뢰도(확률)
- $p(H|E)$ : 새로운 정보($E$)를 받은 후 갱신된 신뢰도, 조건부 확률

$p(H),\; p(H|E)$를  각각 사전 확률(prior probabilty), 사후 확률(posterior probability)이라고 함
- evidence를 관측하기 전 확률, 관측 후 확률로 이해하면 쉬움

$$P(H|E) = \frac{P(E|H)P(H)}{P(E)} , \; P(H) : 사전 확률, \; P(H|E): 사후 확률$$

### 베이즈 정리 Example
#### 문제
질병 A의 발병률이 0.1% 
- 이 질병 보유자를 질병이 있다고 검진할 확률(민감도) 99%
- 미보유자를 질병이 없다고 검진할 확률(특이도) 98%

Q. 어떤 사람이 질병에 걸렸다고 검진 받았을때, 실제 질병에 걸렸을 확률?
#### Solution
여기서 가설(Hypothesis)은 "실제로 병이 있다" 이고 정보(Evidence)는 "진단을 받음" 이다.
따라서, 위에서 문제에서 주어진 정보들을 수식으로 표현하면
- $P(H)$는 실제로 병이 발생했다. $P(H)=0.001$
- $P(E)$는 병이 있다고 진단했다. 
- $P(E|H)$ 는 실제 병이 있는 사람을 질병이 있다고 검진할 확률, $P(E|H)=0.99$
- $P(E^{C}|H^{C})$는 병이 없는 사람을 질병이 없다고 검진할 확률, $P(E^{C}|H^{C})=0.98$

![[2024-09-09-19-37_베이즈 정리.png]]

질문에서 질병이 있다고 검진을 받은 조건에서 실제 질병이 발병할 확률이므로 수식으로 나타내면  다음과 같이 된다. 
$$
\begin{align}
P(H|E) = \frac{P(E|H)P(H)}{P(E)} &= \frac{P(E|H)P(H)}{P(E|H^{C})P(H^{C}) + P(E|H) P(H)} \\
 &= \frac{0.99 \times 0.001}{0.02 \times 0.999 + 0.99 \times0.001}
\end{align}
$$


## Maximum LogLikelihood Estimation, 최대우도법
### 정의
모수적인 데이터 밀도 추정 방법으로 파라미터 $\theta=(\theta_{1}, ..., \theta_{n})$으로 구성된 어떤 확률 밀도 함수 $p(x|\theta)$에서 관측된 표본 데이터 집합을 $X=(x_{1}, x_{2}, ..., x_{n})$이라 할때, 이 표본으로 부터 파라미터 $\theta=(\theta_{1}, ... \theta_n)$을 역산으로 추정하는 방법

#### 예시
예를 들어 다음과 같이 5개의 data sample을 얻었다 가정
$$
x=\{ 1, 4, 5, 6, 9\}
$$
아래 그림에서 2개의 분포중 어떤 분포에서 나왔을 확률이 높은가?

![[2024-09-09-19-37_베이즈 정리-1.png | 500]]

- 빨간색 분포로 부터 추출되었을 확률이 높다. 높은 확률에서 데이터가 추출될 확률이 높으므로?
### Likelihood function
Likelihood는 지금 얻은 데이터가 이 분포로부터 나왔을 가능성을 나타냄, 가능도
계산 방법은 각 데이터 샘플이 위치한 곳에서 해당 분포에 대한 높이(이 분포에서 이 데이터가 나올 확률을 나타냄)를 계산하여 다 곱한 것 (*계산값을 다 더하지 않고 곱하는 이유는 각각의 데이터 샘플이 추출된 사건은 독립 사건)
![[2024-09-09-19-37_베이즈 정리-4.png]]
- $x_{1}$이 $\theta$분포에서 나올 확률은 $p(x_{1}|\theta)$ 
- $x_{2}$이 $\theta$분포에서 나올 확률은 $p(x_{2}|\theta)$ 
- $x_{n}$이 $\theta$분포에서 나올 확률은 $p(x_{n}|\theta)$ 

따라서 전체 데이터 샘플 $X$에 대해서 $\theta$분포에서 나올 확률은 다음과 같이 계산된다.
$$
p(X|\theta) = \prod^{n}_{i=1}{p(x_{i}|\theta)}, \;\; likelihood \; function
$$
보통의 경우 계산상의 용이를 위해 곱셈을 더하기로 바꾸는 log likelihood function을 주로 사용한다.
$$
L(\theta|x) = \log p(x|\theta)= \sum\limits^{n}_{i=1}\log p(x_{i}|\theta)
$$

#### Maximum Log-likelihood Estimation
로그함수는 단조 증가 함수 이기 때문에 log likelihood의 최대값을 찾는 것은 그냥 likelihood의 최대값을 찾는 것과 동일하다. 최대값을 찾기 위해 log likelihood function의 미분을 취하고 기울기가 0인 구간을 찾으면 된다.

$$
\frac{\partial}{\partial\theta} L(\theta|x) = \frac{\partial}{\partial\theta} \log p(x|\theta)= \sum\limits^{n}_{i=1}\frac{\partial}{\partial\theta}\log p(x_{i}|\theta) = 0
$$


---
##### 정리
베이즈 룰을 이용한 방식의 단점 likelihood의 확률분포를 알아야된다.
- 완벽한 확률분포 함수를 얻기 힘듬

그래서 정해지지 않은 몇개의 parameter로 이루어진 함수를 모델링하고 이 모델이 주어진 **Data를 가장 잘 설명하도록 parameter를 구함**

##### 문제 정의
Regression은 연속한 input x를 넣었을때 나오는 output y가 실제 정답 target(t)에 같도록 하는 문제
- 키를 보고 몸무게를 예측하는 모델
- N명의 사람들에 대해 실제 키($x_{i}$)와 동일인물의 실제 몸무게($t_{i}$)를 조사한 Dataset $D$ 
$$
D=\{ (x_{1}, t_{1}), (x_{2}, t_{2}), \cdots, (x_{N}, t_{N})\}
$$
- 적당한 parameter $w$를 설정하여 키($x$)를 넣으면 예측된 몸무게($y$)가 나오는 함수 $y(x|w)$를 정의
	- 여기서 $w$는 $y=a_{n}x^{n}+a_{n-1}x^{n-1} +\cdots+a_{1}x+a_{0}$ 와 같은 함수에서 $a_{n}, \cdots, a_{0}$와 같은 계수를 의미

 - 잘 학습된 모델에서 $t=y(x|w)$ 이 되지만 실제 예측에서 실제 몸무게$(t)$는 예측한 몸무게$(y)$일 확률이 높지만 아닐수도 있다.
	 - 키가 175cm인 사람중에 몸무게가 70kg, 71kg, 90kg와 같이 다양하게 존재하는 데이터의 형태 때문
	 - $x=175$ 입력에 대해서 완벽한 $t$를 예측할 수 없고 그 예측값에 대한 신뢰도만 예측가능함
 - 실제 몸무게($t$)는 예측한 몸무게($y$)를 평균으로 하고 어떤 표준편차 $\sigma$로 하는 가우시안 분포를 따름
$$
\begin{align}
t &\sim N(y(x|w), \sigma^{2}) \\
p(t|x, w, \sigma) &= \frac{1}{\sqrt{2 \pi} \sigma}e^{-\frac{(t - y(x|w))^{2}}{2\sigma^{2}}}
\end{align}
$$
	- 가우시안 분포를 사용하는 이유는 예측한 몸무게를 100% 신뢰하지 못하고 $\sigma$는 예측한 값이 얼마나 불확실한지의 정도를 나타냄

##### MLE

$$
p(t|x) = \frac{1}{\sqrt{2 \pi} \sigma}e^{-\frac{(t - y(x|w))^{2}}{2\sigma^{2}}}
$$
$p(t|x)$는 키가 $x$일 때 실제 몸무게 $t$일 확률이고 Dataset $D$에 대해서 각각 Data에 대해 확률을 구해 곱하면(각 사건은 독립이므로) 전체 Dataset에서 각각에 대한 Data Sample에 대한 확률 곱이 다음과 같이 나온다. 이 확률곱은 모델의 parameter $w$가 각 Data을 예측한 확률의 곱이므로 높으면 높을 수록 이 모델의 정확성이 높다는 뜻이다.
$$
p(D)=\prod^{N}_{i=1}p(t_{i}|x_{i})=\prod^{N}_{i=1} \frac{1}{\sqrt{2 \pi} \sigma}\exp{(-\frac{(t_{i} - y(x_{i}|w))^{2}}{2\sigma^{2}})}
$$
이 모델에 대한 신뢰도는 parameter $w$에 따라 변경되므로 즉 $p(D|w)$으로 표현함이 옳다.
$p(D|w)$가 높으면 각각의 Data에 대한 신뢰도가 높아지므로 이값이 최대가 되는 모델이 가장 이 데이터셋을 잘 예측하는 모델이 되므로 $p(D|w)$가 최대가 되는 값을 찾아야 된다.

##### MLE의 계산
$$
likelihood \; function \; p(D|w) = \prod^{N}_{i=1}p(t_{i}|x_{i})=\prod^{N}_{i=1} \frac{1}{\sqrt{2 \pi} \sigma}\exp{(-\frac{(t_{i} - y(x_{i}|w))^{2}}{2\sigma^{2}})}
$$

위의 likelihood function $p(D|w)$의 최대로 하는 paramter $w$를 계산
미분 계산의 용이를 위해 $log$로 곱을 합으로 바꾼다.
$$
log -likelihood \; function \; \log p(D|w) = \sum\limits^{N}_{i=1}\log p(t_{i}|x_{i})=\sum\limits^{N}_{i=1} \log \Bigl( \frac{1}{\sqrt{2 \pi} \sigma}\exp{(-\frac{(t_{i} - y(x_{i}|w))^{2}}{2\sigma^{2}})} \Bigl)
$$
미분하면
$$
\begin{align}
\frac{\partial}{\partial w} \log p(D|w) &= \frac{\partial}{\partial w}\log \Bigl( \frac{1}{\sqrt{2 \pi} \sigma} \exp{(-\frac{(t_{i} - y(x_{i} | w))^{2}}{2\sigma^{2}})} \Bigl) \\

&= \frac{\partial}{\partial w}\sum\limits^{N}_{i=1} \Bigl[ -\frac{1}{2}\log2 \pi - \log\sigma - \frac{(t_{i}- y(x_{i}|w ))^{2}}{2 \sigma^{2}}  \Bigl]  \\
&= \sum\limits^{N}_{i=1} -\frac{(t_{i} - y(x_{i}|w))}{ \sigma^{2}} =0
\end{align}
$$
$$
\sum\limits^{N}_{i=1}(t_{i} - y(x_{i}|w)) = 0
$$
일때 최대가 된다. $\log p(D|w)$을 최대로 해야되는데 $w$와 관련없는 항들을 지우고 나면
$$
\begin{align}
\underset{w}{maximum} \log{p(D|w)} &= \underset{w}{maximum} \sum\limits^{N}_{i=1} \log \Bigl( \frac{1}{\sqrt{2 \pi} \sigma}\exp{(-\frac{(t_{i} - y(x_{i}|w))^{2}}{2\sigma^{2}})} \Bigl)\\
&= \underset{w}{maximum} \sum\limits^{N}_{i=1} \Bigl[ -\log \sqrt{2 \pi} \sigma - \frac{(t_{i} - y(x_{i}|w))^{2}}{2 \sigma^{2}}\Bigl]\\

&\underset{w}{maximum} \sum\limits^{N}_{i=1} \Bigl[ -(t_{i} - y(x_{i}|w))^{2} \Bigl]\\
&\Rightarrow \underset{w}{minimum} \sum\limits^{N}_{i=1}(t_{i} - y(x_{i}|w))^{2}
\end{align}
$$
L2 Loss로 사용한값이 나오게된다.

##### Maximum A Posterior
사후 확률(Posterior)를 최대화하는 것, Posterior는 Likelihood와 다르게 사전 지식인 Prior가 포함됨
- 주어진 데이터로만 사용하여 parameter $w$를 구하면 MLE
- 데이터와 더불어 사전지식(Prior)를 사용하면 MAP

별다른 사전 지식이 없어도 특정 제약조건을 거는 경우 MAP를 사용할 수 있음(L2, L1 Regularization)

$$
P(w|D) = \frac{P(D|w) P(w)}{\int P(D|w) P(w) dw}
$$

$w$에 대한 특별한 사전 지식을 갖고 있지 않는 상태에서 $w$에 0을 평균으로 하는 가우시안 분포라는 제약 조건을 걸어 준다.
- Overfitting을 방지 하기 위해 네트워크의 표현력을 어느정도 감소시켜야 하는데, parameter $w$의 절대값이 작아야됨
- 어떤 x에 대해 함수를 fitting하면 $y=a_{n}x^{n}+a_{n-1}x^{n-1} + \cdots + a_0$에서 parameter $w$에 해당하는 $a_{n}, \cdots, a_{0}$의 값이 커진다.
$$
\begin{align}
w &\sim N(0, \sigma^{2}_{w}) \\
p(w) &= \frac{1}{\sqrt{2 \pi} \sigma_{w}} e^{-\frac{w^{2}}{2\sigma_{w}^{2}}}
\end{align}
$$

$P(w|D)$를 최대로 하는 $w$를 찾아야 되는데 식으로 나타내면 다음과 같다.
$$
\begin{align}
w^{*} &= \underset{w}{argmax} \log P(w|D)\\
	&= \underset{w}{argmax} \log \frac{P(D|w) P(w)}{P(D)} \\
	&= \underset{w}{argmax} [ -\log P(D) + \log P(D|w) + \log P(w)] 
\end{align}
$$
$\log P(D|w)$는 위에서 $L(w)=\sum\limits^{N}_{i=1}(t_{i} - y(x_{i}|w))^{2}$ 을 최소화 하는 것이고 $P(D)$는 $w$와 상관없는 항이고 $P(w)$는 위에서 제약조건으로 정의한 가우시안 분포함수를 넣으면 다음과 같이 정리된다.
$$
\begin{align}
	w^{*} &= \underset{w}{argmax} \Bigl[-L(w) + \log \frac{1}{\sqrt{2 \pi} \sigma_{w}}e^{-\frac{w^{2}}{2\sigma^{2}_{w}}} \Bigl]\\
	&= \underset{w}{argmax} \Bigl[-L(w) -\log\sqrt{2\pi}\sigma_{w} - \frac{w^{2}}{2\sigma^{2}_{w}}  \Bigl]\\
	  
\end{align}
$$
$w$와 관련이 없거나 상수항인 $\sigma_{w}, P(D)$를 제외하고 마이너스항을 없애고 minimize로 바꿔주면 다음과 같다.
$$
\begin{align}
w^{*} &= \underset{w}{argmin} \Bigl[ L(w) + \frac{w^{2}}{2 \sigma^{2}_{w}} \Bigl]\\
	&= \underset{w}{argmin} \Bigl[ \sum\limits^{N}_{i=1}(t_{i} - y(x_{i}|w))^{2} + \frac{w^{2}}{2 \sigma^{2}_{w}} \Bigl]
\end{align}
$$
L2 Regularization이 적용된 Loss function이 나온다.

##### 나이브 베이즈(Naive Bayes) 분류기
나이브 베이즈 분류기는 베이즈 정리를 이용해 만든 분류기
###### 분류의 확률적 판단 근거	
- 사전지식(Prior)을 이용한 분류 
	예를 들어 정보가 주어지지 않은 상황에서 사람을 데려와 성별을 판단하라고 하면 성별을 5:5이므로 이러한 사전지식을 활용해 어림짐작으로 50%확률로 판단할 수 있음. 
	다른 예로, 삼색 고양이를 데려와 성별을 묻는다면 "삼색고양이는 거의 암컷" 이라는 사전지식을 아는사람은 이를 활용해 높은 신뢰도로 암컷이라고 분류할 수 있음.
	이와 같이 test sample의 어떠한 정보(feature) 없이 사전 지식 만으로 분류 할 수 있고 이렇게 분류에 도움을 줄 수 있는 확률을 사전 확률(Prior Probabilty)라고 함.
	* test data sample이 A: 40개, B: 30개, C: 30개이 주어지면 각각에 대한 갯수가 사전 지식이 되므로 각 class에 대한 사전확률이 $P(A) =0.4, \, P(B)=0.3, \, P(C)=0.3$ 이 된다.
* 특정 정보(feature)가 추가되는 경우 (likelihood)
	키(특정 정보, feature)에 따라 이 사람이 남자인지 여자인지 판별하는 문제에서 다음이 training sample을 통해 얻은 키에 대한 분포라고 할 때
	![[2024-09-09-19-37_베이즈 정리-5.png | 600]]
	가령 키가 175cm인 표본 x의 성별을 판단하면 위 확률 분포에서 여자, 남자에 각각에 대한 likelihood값을 비교하면 $P(175cm|male)>P(175cm|female)$ 이므로 남자일 가능성이 커 보인다.
	>위의 likelihood만으로 비교 근거가 충분한가?
	>	근거가 부족하다. 어떤 특정 지역의 남녀 성비 분포가 불균형하다면(여자가 99명이고 남자가 1명일 정도로) 위의 likelihood만으로 남자라고 판단하기 어렵기 때문에 사전 지식(Prior)인 남녀 성비에 대한 확률이 필요하다.
	
	따라서, 사전 지식인 $P(male)=0.01, \; P(female)=0.99$인 사전 지식과 위의 likelihood를 곱한 값을 비교하면 여자일 확률이 더 높게 나온다.
	$$
		P(175cm|female)\cdot P(female)=0.099 >P(175cm|male)\cdot P(male)=0.004
	$$
- 정보(feature)가 더 추가되는 경우
	키뿐만 아니라 몸무게에 대한 정보도 추가되면 다음과 같이 비교 가능하다.
	$$
	P(female)\cdot P(175cm|female) \cdot P(85kg|female) > P(male)\cdot P(175cm|male) \cdot P(85kg|male) 
$$
- 베이즈(Bayes) 정리를 통해 판단 근거 도출
	어떤 근거에 대한 판단 근거는 사후 확률(Posterior Probability)로 판단 할 수 있음 어떤 feature값들을 보고 그 class인지를 판단하므로 $P(C|feature)$, 즉 $P(female|175cm), \; P(male|175cm)$의 확률을 구해 비교하면 된다.  
	$$
	\begin{align}
	P(female|175cm) &= \frac{P(175cm|female) \cdot P(female)}{P(175cm)} \\
	P(male|175cm) &= \frac{P(175cm|male) \cdot P(male)}{P(175cm)} \\
	\frac{P(175cm|female) \cdot P(female)}{P(175cm)} &> \frac{P(175cm|male) \cdot P(male)}{P(175cm)} \\
	\end{align}
	$$
	사후 확률 비교에서 밑변은 $P(175cm)$로 같으므로 분자만 비교하면 되는데 분자 형태가 아까 $likelihood \times prior$의 형태이므로 수학적으로 분류의 근거가 된다.
	
- 데이터의 정보(feature)가 여러개일 때
	여러개의 정보(feature)로 Class를 판별할 때의 사후 확률은 다음과 같다.
	$$
		P(C_{1}|f_{1}, f_{2}, \cdots, f_{n}), \; P(C_{2}|f_{1},f_{2},\cdots,f_{n})
	$$
	> 확률과 통계 식
	>  $$
	  \begin{align}
	  & P(X \cap Y)=P(X, Y)=P(X|Y)\cdot P(Y)=P(Y|X) \cdot P(X) \\
	  &P(X,Y,Z)=P(X|Y,Z)\cdot P(Y,Z)=P(X|Y,Z)\cdot P(Y|Z) \cdot P(Z) \quad\quad (chain \; rule)
	  \end{align}
	  $$
	
	위 식으로 2개의 Class에 대한 사후 확률 식을 전개하면
	$$
	\begin{align}
		P(C_{1},f_{1},f_{2}, \cdots,f_{n}) &= P(f_{1}|f_{2},\cdots,f_n,C_{1}) \cdot P(f_{2},\cdots,f_n,C_{1}) \\
		&= P(f_{1}|f_{2},\cdots,f_n,C_{1}) \cdot P(f_{2}|\cdots,f_n,C_{1}) \cdot P(\cdots,f_{n},C_{1})\\
		&= P(f_{1}|f_{2},\cdots,f_n,C_{1}) \cdot P(f_{2}|\cdots,f_n,C_{1}) \cdots P(f_{n} |C_{1}) \cdot P(C_{1}) \quad\quad (f_{1}, f_{2}, \cdots,f_{n}은 \; 독립 )\\ 
		&= P(f_{1}|C_{1}) \cdot P(f_{2}|C_{1}) \cdots P(f_{n} |C_{1}) \cdot P(C_{1}) \\
		P(C_{1},f_{1},f_{2}, \cdots, f_{n}) &= P(C_{1}|f_{1}, f_{2}, \cdots, f_{n}) \cdot P(f_{1}, f_{2}, \cdots, f_{n}) \\\\
		P(C_{1}|f_{1},f_{2}, \cdots, f_{n}) &= \frac{P(f_1|C_{1})\cdot P(f_{2}|C_{2})\cdots P(f_{n}|C_{1}) \cdot P(C_{1})}{P(f_{1}, f_{2},\cdots, f_{n})} = \frac{P(C_{1}) \cdot \prod^{n}_{i=1}P(f_{i}|C_{1})}{P(f_{1},f_{2},\cdots, f_{n})}\\
		P(C_{2}|f_{1},f_{2}, \cdots, f_{n}) &= \frac{P(f_1|C_{2})\cdot P(f_{2}|C_{2})\cdots P(f_{n}|C_{2}) \cdot P(C_{2})}{P(f_{1}, f_{2},\cdots, f_{n)}}= \frac{P(C_{2}) \cdot \prod^{n}_{i=1}P(f_{i}|C_{2})}{P(f_{1},f_{2},\cdots, f_{n})}
	\end{align}
	$$


	각 Class에 대한 사후 확률을 비교할 때 분모 $P(f_{1},\cdots, f_{n})$가 같으므로  분자인 likelihood의 곱인 $likelihood \times prior$만 비교하면 된다.
##### GMM과 EM 알고리즘

$$
P(x | \mu, \Sigma) = \frac{1}{(2 \pi)^{0.5d} |\Sigma|^{0.5}} \exp \Bigl[ \frac{1}{2}(x - \mu)^{T} \Sigma^{-1} (x - \mu) \Bigl]
$$









 